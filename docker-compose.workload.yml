# Dummy workload for testing the AI Portainer Dashboard
# Deploy with: ./scripts/deploy-workload.sh start
# Do NOT use docker compose directly — use the deploy script.
#
# 26 services total:
#   - 12 healthy baseline (web, db, mq, workers, monitoring, staging, dev)
#   - 10 issue containers (anomaly, security, health, crash, log, stopped)
#   - 4 inter-container traffic (gateway, api, worker-queue, cron)
#
# Detection coverage:
#   Anomaly:     memory-hog (mem spikes), cpu-burster (CPU spikes)
#   Security:    privileged-risk (3 findings), network-risk (3 findings), no-healthcheck (1)
#   Health:      health-degrader (unhealthy after 2min), health-flapper (random)
#   Remediation: crash-loop, health-degrader, health-flapper, memory-hog, stopped-service
#   Topology:    app-gateway, app-api, app-worker-queue, app-cron (multi-network)

services:
  # ============================================================
  # HEALTHY BASELINE — 12 services (production, staging, dev)
  # ============================================================

  # === Web Tier ===
  web-frontend:
    image: nginx:alpine
    container_name: web-frontend
    ports:
      - "8080:80"
    labels:
      app.tier: "web"
      app.env: "production"
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  web-backend-1:
    image: httpd:alpine
    container_name: web-backend-1
    labels:
      app.tier: "web"
      app.env: "production"
      app.role: "backend"
    healthcheck:
      test: ["CMD", "httpd", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  web-backend-2:
    image: httpd:alpine
    container_name: web-backend-2
    labels:
      app.tier: "web"
      app.env: "production"
      app.role: "backend"
    healthcheck:
      test: ["CMD", "httpd", "-t"]
      interval: 30s
      timeout: 10s
      retries: 3
    restart: unless-stopped

  # === Database Tier ===
  db-postgres:
    image: postgres:16-alpine
    container_name: db-postgres
    environment:
      POSTGRES_USER: app
      POSTGRES_PASSWORD: secret123
      POSTGRES_DB: appdb
    volumes:
      - postgres-data:/var/lib/postgresql/data
    labels:
      app.tier: "database"
      app.env: "production"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U app -d appdb"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - default
      - app-backend-net
    restart: unless-stopped

  db-redis:
    image: redis:7-alpine
    container_name: db-redis
    command: redis-server --maxmemory 64mb --maxmemory-policy allkeys-lru
    labels:
      app.tier: "cache"
      app.env: "production"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - default
      - app-backend-net
    restart: unless-stopped

  # === Message Queue ===
  mq-rabbitmq:
    image: rabbitmq:3-management-alpine
    container_name: mq-rabbitmq
    ports:
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: admin123
    labels:
      app.tier: "messaging"
      app.env: "production"
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_running"]
      interval: 30s
      timeout: 10s
      retries: 5
    networks:
      - default
      - app-backend-net
    restart: unless-stopped

  # === Workers ===
  worker-1:
    image: alpine:latest
    container_name: worker-1
    command: sh -c "while true; do echo 'Worker 1 processing...'; sleep 10; done"
    labels:
      app.tier: "worker"
      app.env: "production"
    restart: unless-stopped

  worker-2:
    image: alpine:latest
    container_name: worker-2
    command: sh -c "while true; do echo 'Worker 2 processing...'; sleep 15; done"
    labels:
      app.tier: "worker"
      app.env: "production"
    restart: unless-stopped

  # === Monitoring ===
  monitoring-prometheus:
    image: prom/prometheus:latest
    container_name: monitoring-prometheus
    ports:
      - "9090:9090"
    labels:
      app.tier: "monitoring"
      app.env: "infrastructure"
    restart: unless-stopped

  # === Staging Environment ===
  staging-web:
    image: nginx:alpine
    container_name: staging-web
    labels:
      app.tier: "web"
      app.env: "staging"
    restart: unless-stopped

  staging-api:
    image: httpd:alpine
    container_name: staging-api
    labels:
      app.tier: "api"
      app.env: "staging"
    restart: unless-stopped

  # === Development Environment ===
  dev-web:
    image: nginx:alpine
    container_name: dev-web
    labels:
      app.tier: "web"
      app.env: "development"
    restart: "no"

  # ============================================================
  # ISSUE CONTAINERS — 10 services (anomaly, security, health)
  # ============================================================

  # --- Anomaly Detection Triggers ---

  # Memory stress: constant ~100MB allocation against 256MB limit
  # Triggers: memory anomaly detection after baseline established
  memory-hog:
    image: alpine:latest
    container_name: memory-hog
    command: >
      sh -c "
      echo '[memory-hog] Allocating ~100MB...';
      dd if=/dev/zero bs=1M count=100 of=/dev/shm/memfill 2>/dev/null;
      echo '[memory-hog] Holding allocation';
      while true; do sleep 30; done"
    mem_limit: 256m
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "memory-pressure"
    restart: unless-stopped

  # Intermittent CPU spikes: 15s high CPU, 45s idle, repeat
  # Triggers: CPU anomaly detection (low baseline, periodic spikes)
  cpu-burster:
    image: alpine:latest
    container_name: cpu-burster
    command: >
      sh -c "while true; do
        echo \"[cpu-burster] Spike start\";
        timeout 15 dd if=/dev/zero of=/dev/null bs=1M 2>/dev/null || true;
        echo \"[cpu-burster] Spike end, sleeping\";
        sleep 45;
      done"
    cpus: 1.0
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "cpu-spikes"
    restart: unless-stopped

  # --- Crash & Restart Triggers ---

  # Crashes every ~10s and restarts forever
  # Triggers: restart loop remediation, restart count alerts
  crash-loop:
    image: alpine:latest
    container_name: crash-loop
    command: sh -c "echo 'Starting...'; sleep 10; exit 1"
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "crash-loop"
    restart: always

  # --- Health Check Triggers ---

  # Starts healthy, becomes unhealthy after ~2 minutes
  # Triggers: health check failure detection, unhealthy remediation
  health-degrader:
    image: alpine:latest
    container_name: health-degrader
    command: >
      sh -c "echo 'Starting healthy...';
      sleep 120;
      touch /tmp/unhealthy;
      echo 'Now unhealthy!';
      while true; do sleep 30; done"
    healthcheck:
      test: ["CMD-SHELL", "[ ! -f /tmp/unhealthy ]"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "health-degradation"
    restart: unless-stopped

  # Health status flips randomly every 15-30s
  # Triggers: health flapping, intermittent unhealthy alerts
  health-flapper:
    image: alpine:latest
    container_name: health-flapper
    command: >
      sh -c "touch /tmp/healthy;
      while true; do
        DELAY=$$(( RANDOM % 16 + 15 ));
        sleep $$DELAY;
        if [ -f /tmp/healthy ]; then
          rm /tmp/healthy;
          echo '[health-flapper] Now UNHEALTHY';
        else
          touch /tmp/healthy;
          echo '[health-flapper] Now HEALTHY';
        fi;
      done"
    healthcheck:
      test: ["CMD-SHELL", "[ -f /tmp/healthy ]"]
      interval: 10s
      timeout: 5s
      retries: 1
      start_period: 5s
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "health-flapping"
    restart: unless-stopped

  # --- Log Volume Trigger ---

  # Bursts of 500 error-like log lines every 30s
  # Triggers: high log volume observable in container details
  log-spammer:
    image: alpine:latest
    container_name: log-spammer
    command: >
      sh -c "while true; do
        echo '[log-spammer] Starting log burst...';
        for i in $$(seq 1 500); do
          echo \"ERROR $$(date -Iseconds) [svc.handler] Request failed: connection timeout after 30000ms - upstream=10.0.$$((RANDOM % 256)).$$((RANDOM % 256)):8080 trace_id=$$(cat /proc/sys/kernel/random/uuid 2>/dev/null || echo $$RANDOM$$RANDOM)\";
        done;
        echo '[log-spammer] Burst complete, sleeping 30s';
        sleep 30;
      done"
    logging:
      driver: json-file
      options:
        max-size: "10m"
        max-file: "1"
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "log-flooding"
    restart: unless-stopped

  # --- Security Scanner Triggers ---

  # Privileged + root + SYS_ADMIN = 3 security findings
  # Triggers: security scanner (privileged mode, SYS_ADMIN cap, root user)
  privileged-risk:
    image: alpine:latest
    container_name: privileged-risk
    command: sleep infinity
    privileged: true
    user: "0:0"
    cap_add:
      - SYS_ADMIN
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "security-privileged"
    restart: unless-stopped

  # Host network + NET_ADMIN + SYS_PTRACE = 3 security findings
  # Triggers: security scanner (host network, NET_ADMIN cap, SYS_PTRACE cap)
  network-risk:
    image: alpine:latest
    container_name: network-risk
    command: sleep infinity
    network_mode: host
    cap_add:
      - NET_ADMIN
      - SYS_PTRACE
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "security-network"
    restart: unless-stopped

  # Running nginx without a healthcheck = 1 security finding
  # Triggers: security scanner (missing healthcheck)
  no-healthcheck:
    image: nginx:alpine
    container_name: no-healthcheck
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "missing-healthcheck"
    restart: unless-stopped

  # --- Stopped Container ---

  # Exits immediately and stays stopped
  # Triggers: stopped container detection, start remediation suggestion
  stopped-service:
    image: alpine:latest
    container_name: stopped-service
    command: echo "Exited on purpose"
    labels:
      app.tier: "test"
      app.env: "test"
      app.issue: "stopped"
    restart: "no"

  # ============================================================
  # INTER-CONTAINER TRAFFIC — 4 services (multi-network topology)
  # ============================================================
  # These containers actively communicate with each other, making
  # them visible as connected nodes in the network topology view.
  # They bridge app-frontend-net and app-backend-net for a
  # realistic multi-tier architecture.

  # API gateway that proxies to app-api — bridges frontend and backend nets
  app-gateway:
    image: nginx:alpine
    container_name: app-gateway
    command:
      - sh
      - -c
      - |
        printf 'server {\n  listen 80;\n  location / {\n    return 200 "gateway ok\\n";\n    add_header Content-Type text/plain;\n  }\n  location /api {\n    proxy_pass http://app-api:8000;\n    proxy_connect_timeout 2s;\n    proxy_read_timeout 5s;\n  }\n}\n' > /etc/nginx/conf.d/default.conf
        nginx -g 'daemon off;'
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - app-frontend-net
      - app-backend-net
    labels:
      app.tier: "gateway"
      app.env: "production"
      app.role: "proxy"
    restart: unless-stopped

  # Simple API server that queries Redis and Postgres every 10s
  app-api:
    image: alpine:latest
    container_name: app-api
    command: >
      sh -c "
      while true; do
        echo \"[app-api] Pinging db-redis...\";
        nc -z -w2 db-redis 6379 && echo '  redis: OK' || echo '  redis: FAIL';
        echo \"[app-api] Pinging db-postgres...\";
        nc -z -w2 db-postgres 5432 && echo '  postgres: OK' || echo '  postgres: FAIL';
        sleep 10;
      done"
    networks:
      - app-backend-net
    labels:
      app.tier: "api"
      app.env: "production"
      app.role: "backend"
    restart: unless-stopped

  # Worker that polls RabbitMQ every 15s
  app-worker-queue:
    image: alpine:latest
    container_name: app-worker-queue
    command: >
      sh -c "
      while true; do
        echo \"[app-worker-queue] Polling mq-rabbitmq...\";
        nc -z -w2 mq-rabbitmq 5672 && echo '  rabbitmq: OK' || echo '  rabbitmq: FAIL';
        sleep 15;
      done"
    networks:
      - app-backend-net
    labels:
      app.tier: "worker"
      app.env: "production"
      app.role: "consumer"
    restart: unless-stopped

  # Scheduled job that hits the API gateway every 30s
  app-cron:
    image: alpine:latest
    container_name: app-cron
    command: >
      sh -c "
      while true; do
        echo \"[app-cron] Hitting app-gateway...\";
        wget -q -O- --timeout=5 http://app-gateway/ 2>&1 || echo '  gateway: FAIL';
        sleep 30;
      done"
    networks:
      - app-frontend-net
    labels:
      app.tier: "cron"
      app.env: "production"
      app.role: "scheduler"
    restart: unless-stopped

volumes:
  postgres-data:

networks:
  default:
    name: workload-net
  app-frontend-net:
    name: app-frontend-net
  app-backend-net:
    name: app-backend-net
