# Architecture

This document provides a high-level overview of the system's architecture, key components, and data flows. The system appears to be a complex AI-powered agent capable of understanding user queries, searching for information, executing code, and presenting results in a rich user interface.

## 1. High-Level Components

The system is composed of several major subsystems that work together:

-   **Orchestration Engine:** (Implied by `ModularStrategy` and React components like `RenderStepExecution`). This central component seems to manage the overall workflow of a user request, breaking it down into steps, executing them, and managing state.
-   **Model Abstraction Layer:** A layer that provides a unified interface to interact with various Large Language Models (LLMs), both local (GGUF-based) and remote (via APIs like LiteLLM).
-   **Code Execution Subsystem:** A critical component that provides sandboxed environments for executing code generated by the LLM.
-   **Search & Data Retrieval:** Tools for searching external sources, like the `search_code` function for GitHub.
-   **Frontend UI:** A rich user interface built with React for rendering the complex interactions, steps, and results from the agent.

## 2. Core Architectural Patterns

The project follows a **Monorepo** structure with a **Client-Server (Full-stack)** architectural pattern, specifically designed around an **Observer-First** principle.

### Key Patterns

*   **Layered Backend:** The backend is organized into functional layers:
    *   `routes/`: REST API endpoints.
    *   `services/`: Business logic and external integrations (Portainer, Ollama, Redis, Harbor).
    *   `models/`: Zod schemas and database query logic.
    *   `scheduler/`: Background jobs for metrics collection and anomaly detection. Endpoints and containers are processed in parallel (`METRICS_ENDPOINT_CONCURRENCY`, `METRICS_CONTAINER_CONCURRENCY`) with a mutex guard to prevent overlapping cycles.
*   **Frontend State Management:**
    *   **Server State:** Managed by **TanStack React Query** for caching and synchronization.
    *   **UI State:** Managed by **Zustand** for lightweight client-side state.
*   **Observer-First Design:** A core project philosophy where visibility is prioritized, and any state-mutating actions (like restarting containers) are strictly opt-in and gated by a **Remediation Approval** workflow.
*   **Real-Time Subsystems:** Uses Socket.IO namespaces (`/llm`, `/monitoring`, `/remediation`) to push live insights and handle streaming AI chat.
*   **Security-First:** Implements **RBAC (Role-Based Access Control)** by default, requiring administrative roles for all mutating endpoints, alongside specialized **Prompt Injection Guards** for LLM safety.
*   **Modular Agent Strategy:** For AI features, it uses a modular strategy that includes multi-stage search pipelines and flexible code execution environments (In-process, Dockerized, or Remote).

## 3. Code Execution Subsystem

The system employs multiple strategies for code execution, likely chosen based on the security context, required dependencies, and the nature of the code being run. This provides a flexible and security-conscious approach.

### Execution Strategies

1.  **In-Process Execution (`exec`)**:
    *   **Implementation:** Uses Python's built-in `exec()` function.
    *   **Sandboxing:** Attempts to isolate the execution context by preparing a `globals` dictionary.
    *   **Use Case:** Likely used for simple, trusted Python snippets that don't require external dependencies or strict isolation. It is the fastest but least secure method.

2.  **Containerized Execution (Docker)**:
    *   **Implementation:** Uses a container (e.g., Docker) to run code via `self._container.exec_run`.
    *   **Sandboxing:** Provides strong isolation at the OS level. The code runs in a separate, ephemeral environment, preventing it from accessing the host system.
    *   **Use Case:** Ideal for untrusted code, code with complex dependencies (which can be pre-installed in the Docker image), or when a specific environment is required.

3.  **Remote Interpreter Service (`_code_interpreter_extension`)**:
    *   **Implementation:** Delegates execution to an external service or extension.
    *   **Sandboxing:** The security model is managed entirely by the remote service, providing a strong separation of concerns.
    *   **Use Case:** Used when leveraging a managed, stateful code execution environment that may provide additional features like file handling, state persistence across calls, and pre-installed libraries.

The `BaseCodeExecutor` abstract class provides a common interface for these different implementations, allowing the orchestration engine to use them interchangeably.

## 3. Model Abstraction Layer

The system uses a sophisticated abstraction layer to handle interactions with different LLMs.

-   **`BaseModel`:** Defines the abstract interface for all models.
-   **GGUF-based Models (`LlamaModel`, `ArcticModel`, etc.):** These classes provide specialized handling for running local models in GGUF format. They contain model-specific logic for tasks like tensor manipulation (`modify_tensors`) and vocabulary setup (`set_vocab`), which are necessary to adapt different architectures to a common inference engine.
-   **API-based Models (`LitellmModel`):** This acts as an adapter for `litellm`, allowing the system to use hundreds of different models from providers like OpenAI, Google, Anthropic, etc. It handles the translation between the system's internal data format and the API provider's format.

<h2>4. Search and Data Processing Pipelines</h2>

The system includes complex pipelines for processing data and executing multi-step logic.

<h3><code>ModularStrategy</code> Search Pipeline</h3>

The `ModularStrategy.search` method implements a sophisticated, multi-stage search process. A high-level view of this pipeline is:

1.  **Constraint Analysis:** A user query is analyzed to extract initial constraints.
2.  **LLM-Powered Query Generation:** An LLM expands on the initial constraints to generate a set of intelligent search queries.
3.  **Candidate Exploration:** The generated queries are used to explore various sources and gather raw candidate results in parallel.
4.  **Asynchronous Evaluation:** Candidates are placed in a background queue and evaluated against the constraints using a `ConstraintChecker`.
5.  **Selection:** The best-evaluated candidate is selected.
6.  **Answer Generation:** The final answer is generated based on the best candidate, potentially using another LLM call.

*A detailed sequence or data flow diagram is recommended to fully document the interactions between the components (`ConstraintAnalyzer`, `LLMConstraintProcessor`, `CandidateExplorer`, etc.) in this pipeline.*

<h2>5. Frontend Architecture</h2>

The frontend is built with **React** and uses **Tailwind CSS** for styling, indicating a modern, component-based architecture.

-   **Conditional Rendering:** Components like `ChatMessage` use extensive conditional logic to render different types of messages (user vs. agent, plan vs. execution, tool call vs. final answer). This creates a dynamic and responsive user experience.
-   **Stateful Logic:** Components use React hooks (`useState`, `useEffect`) to manage local UI state, such as expanding/collapsing content (`TruncatedContent`) or tracking step status.
-   **Component-based Styling:** The use of `[&_....]:` syntax in Tailwind CSS suggests a pattern of styling child components from a parent, which helps in creating self-contained and reusable UI elements.


## Architecture Map (Route → Service/Data)

Backend request flow is organized by route modules, with most Portainer-facing routes using the Portainer client + cache/normalizers. App data (sessions, settings, insights, etc.) is stored in PostgreSQL. Time-series metrics use TimescaleDB.

| Route Area | Primary Routes | Service/Data Dependencies |
|---|---|---|
| Auth | `/api/auth/*` | `services/session-store.ts`, `services/audit-logger.ts` |
| OIDC | `/api/auth/oidc/*` | `services/oidc.ts`, `services/session-store.ts`, `services/audit-logger.ts` |
| Dashboard | `/api/dashboard/summary` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Endpoints | `/api/endpoints*` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Containers | `/api/containers*` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Container Logs | `/api/containers/:eid/:cid/logs` | `services/portainer-client.ts` |
| Images | `/api/images*` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Networks | `/api/networks*` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Stacks | `/api/stacks*` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Search | `/api/search` | `services/portainer-client.ts`, `services/portainer-cache.ts`, `services/portainer-normalizers.ts` |
| Metrics | `/api/metrics*` | TimescaleDB via `db/timescale.ts` |
| Monitoring | `/api/monitoring/*` | PostgreSQL via `db/app-db-router.ts` |
| Remediation | `/api/remediation/*` | `services/portainer-client.ts`, `services/audit-logger.ts`, PostgreSQL |
| Settings | `/api/settings*` | PostgreSQL via `db/app-db-router.ts`, `services/audit-logger.ts` |
| Logs | `/api/logs/*` | `services/notification-service.ts` (test), optional external log backend |
| Traces | `/api/traces*` | PostgreSQL via `db/app-db-router.ts` |
| Investigations | `/api/investigations*` | `services/investigation-store.ts` (PostgreSQL) |
| Backup | `/api/backup*` | `services/backup-service.ts` (pg_dump/pg_restore), `services/audit-logger.ts` |
| Cache Admin | `/api/admin/cache/*` | `services/portainer-cache.ts`, `services/audit-logger.ts` |
| Harbor | `/api/harbor/*` | `services/harbor-client.ts`, `services/harbor-sync.ts`, `services/settings-store.ts`, PostgreSQL |
| PCAP | `/api/pcap/*` | `services/pcap-service.ts`, `services/audit-logger.ts` |
| Health | `/health`, `/health/ready`, `/health/ready/detail` | `db/postgres.ts`, `db/timescale.ts`, `services/portainer-cache.ts` (Redis ping) |

## System Overview

<div align="left">

```mermaid
graph LR
    subgraph Frontend["&nbsp; Frontend — React 19 + Vite 6 :5273 &nbsp;"]
        direction TB
        Router["React Router v7<br/><i>28 lazy-loaded pages</i>"]

        subgraph Pages["&nbsp; Pages &nbsp;"]
            direction LR
            P1["Home<br/>Fleet Overview"]
            P2["Workload Explorer<br/>Stack Overview"]
            P3["Container Detail<br/>Container Health"]
            P4["Container Comparison<br/>Image Footprint"]
            P5["Network Topology<br/>AI Monitor"]
            P6["Metrics Dashboard<br/>Remediation"]
            P7["Trace Explorer<br/>LLM Assistant"]
            P8["LLM Observability<br/>Edge Logs"]
            P9["Log Viewer<br/>Packet Capture"]
            P10["Investigations<br/>Investigation Detail"]
            P11["Security Audit<br/>Status Page"]
            P12["Webhooks<br/>Users"]
            P13["Backups<br/>Reports"]
            P14["Settings<br/>Login"]
        end

        subgraph FState["&nbsp; State &nbsp;"]
            direction LR
            RQ["TanStack Query 5<br/><i>Server state</i>"]
            Zustand["Zustand 5<br/><i>UI state</i>"]
            SIOClient["Socket.IO<br/><i>3 namespaces</i>"]
        end

        subgraph FUI["&nbsp; UI Layer &nbsp;"]
            direction LR
            Radix["Radix UI"]
            Recharts["Recharts"]
            XYFlow["XYFlow"]
            Tailwind["Tailwind v4"]
        end

        Router --> Pages
        Pages --> FState
        Pages --> FUI
    end

    subgraph Backend["&nbsp; Backend — Fastify 5 + TypeScript :3051 &nbsp;"]
        direction TB
        API["REST API<br/><i>34 route modules</i>"]

        subgraph Sockets["&nbsp; Socket.IO &nbsp;"]
            direction LR
            NSllm["/llm"]
            NSmon["/monitoring"]
            NSrem["/remediation"]
        end

        subgraph Services["&nbsp; Services — 35 modules &nbsp;"]
            direction TB
            subgraph SvcRow1[" "]
                direction LR
                SvcCore["<b>Core</b><br/>Portainer Client · Circuit Breaker<br/>Normalizers · Hybrid Cache<br/>LLM Client · LLM Tools · Event Bus"]
                SvcAI["<b>AI &amp; Detection</b><br/>Anomaly Detection · Isolation Forest<br/>Anomaly Explainer · NLP Log Analyzer<br/>Predictive Alerting"]
                SvcMetrics["<b>Monitoring &amp; Metrics</b><br/>Monitoring · Metrics Collector<br/>Metric Correlator · LTTB Decimator<br/>Capacity Forecaster"]
            end
            subgraph SvcRow2[" "]
                direction LR
                SvcIncident["<b>Incidents &amp; Response</b><br/>Incident Correlator · Summarizer<br/>Alert Similarity · Investigation<br/>Remediation"]
                SvcTrace["<b>Tracing &amp; Security</b><br/>Trace Store · OTLP Transformer<br/>PCAP Service · PCAP Analysis<br/>Security Scanner · Image Staleness<br/>Harbor Client · Harbor Sync"]
                SvcInfra["<b>Infrastructure</b><br/>OIDC · Session Store · Audit Logger<br/>Notifications · Webhooks · Backup<br/>ES Forwarder · Kibana Client"]
            end
        end

        subgraph Scheduler["&nbsp; Scheduler &nbsp;"]
            direction LR
            J1(["Metrics<br/><i>60s</i>"])
            J2(["Monitoring<br/><i>5min</i>"])
            J3(["Cleanup<br/><i>daily</i>"])
            J4(["Harbor Sync<br/><i>30min</i>"])
        end

        DB[("PostgreSQL 17")]

        API --> Services
        Sockets --> Services
        Scheduler --> Services
        Services --> DB
    end

    subgraph Bottom[" "]
        direction TB

        subgraph Schema["&nbsp; DB Schema — 22 tables (PostgreSQL) &nbsp;"]
            direction TB
            subgraph SchemaRow1[" "]
                direction LR
                T1["sessions"]
                T2["settings"]
                T3["insights"]
                T4["metrics"]
                T5["actions"]
            end
            subgraph SchemaRow2[" "]
                direction LR
                T6["spans"]
                T7["audit_log"]
                T8["investigations"]
                T9["incidents"]
                T10["users"]
            end
            subgraph SchemaRow3[" "]
                direction LR
                T11["pcap_captures"]
                T12["webhooks"]
                T13["webhook_deliveries"]
                T14["notification_log"]
                T15["llm_traces"]
            end
            subgraph SchemaRow4[" "]
                direction LR
                T16["kpi_snapshots"]
                T17["image_staleness"]
                T18["monitoring_cycles"]
                T19["monitoring_snapshots"]
            end
            subgraph SchemaRow5[" "]
                direction LR
                T20["ebpf_coverage"]
                T21["mcp_servers"]
                T22["prompt_profiles"]
            end
        end

        subgraph External["&nbsp; External Services &nbsp;"]
            direction TB
            subgraph ExtRow1[" "]
                direction LR
                Portainer(["Portainer API"])
                Ollama(["Ollama LLM"])
            end
            subgraph ExtRow2[" "]
                direction LR
                Redis(["Redis"])
                Kibana(["Elasticsearch"])
                TimescaleDB(["TimescaleDB"])
                Harbor(["Harbor Registry"])
            end
        end
    end

    %% Frontend to Backend
    RQ -- "HTTP /api/*" --> API
    SIOClient -- "WebSocket" --> Sockets

    %% Backend to External
    SvcCore -- "REST" --> Portainer
    SvcCore -- "API" --> Ollama
    SvcCore -- "cache" --> Redis
    SvcInfra -. "optional" .-> Kibana
    SvcTrace -- "REST v2.0" --> Harbor
    SvcMetrics -. "scale" .-> TimescaleDB

    %% Database
    DB --> Schema

    %% --- Styling ---
    classDef external fill:#eff6ff,stroke:#3b82f6,stroke-width:2px,color:#1e40af
    classDef frontend fill:#f0f9ff,stroke:#0ea5e9,stroke-width:1.5px,color:#0c4a6e
    classDef backend fill:#f0fdf4,stroke:#22c55e,stroke-width:1.5px,color:#14532d
    classDef scheduler fill:#faf5ff,stroke:#a855f7,stroke-width:1.5px,color:#581c87
    classDef data fill:#fffbeb,stroke:#f59e0b,stroke-width:2px,color:#78350f
    classDef invisible fill:none,stroke:none

    class Portainer,Ollama,Kibana,Redis,TimescaleDB external
    class Router,P1,P2,P3,P4,P5,P6,P7,P8,P9,P10,P11,P12,P13,P14,RQ,Zustand,SIOClient,Radix,Recharts,XYFlow,Tailwind frontend
    class API,NSllm,NSmon,NSrem backend
    class SvcCore,SvcAI,SvcMetrics,SvcIncident,SvcTrace,SvcInfra backend
    class J1,J2,J3 scheduler
    class DB,T1,T2,T3,T4,T5,T6,T7,T8,T9,T10,T11,T12,T13,T14,T15,T16,T17,T18,T19,T20,T21,T22 data
    class Bottom,SvcRow1,SvcRow2,SchemaRow1,SchemaRow2,SchemaRow3,SchemaRow4,SchemaRow5,ExtRow1,ExtRow2 invisible
```

</div>

## Data Flow

<div align="left">

```mermaid
sequenceDiagram
    actor User
    participant FE as Frontend
    participant API as REST API
    participant WS as Socket.IO
    participant Sched as Scheduler
    participant Port as Portainer
    participant LLM as Ollama
    participant DB as PostgreSQL

    rect rgba(59, 130, 246, 0.05)
        Note over User,DB: Authentication
        User->>FE: Login
        FE->>API: POST /api/auth/login
        API->>DB: Create session
        API-->>FE: JWT token
        FE-->>User: Redirect to dashboard
    end

    rect rgba(34, 197, 94, 0.05)
        Note over User,DB: Dashboard Data
        User->>FE: Navigate to page
        FE->>API: GET /api/containers
        API->>Port: Fetch containers
        Port-->>API: Container data
        API-->>FE: Normalized response
        FE-->>User: Render UI
    end

    rect rgba(168, 85, 247, 0.05)
        Note over User,DB: Real-Time Monitoring
        Sched->>Port: Collect metrics (60s)
        Port-->>Sched: CPU/memory stats
        Sched->>DB: Store metrics
        Sched->>Sched: Anomaly detection (5min)
        Sched->>DB: Store insights
        Sched->>WS: Broadcast
        WS-->>FE: Push to /monitoring
        FE-->>User: Live update
    end

    rect rgba(245, 158, 11, 0.05)
        Note over User,DB: AI Chat
        User->>FE: Send message
        FE->>WS: Emit to /llm
        WS->>Port: Fetch context
        WS->>LLM: Stream request
        LLM-->>WS: Token stream
        WS-->>FE: Stream tokens
        FE-->>User: Render markdown
    end
```

</div>

## Tech Stack

| Layer | Technologies |
|-------|-------------|
| **Frontend** | React 19, TypeScript 5.7, Vite 6, Tailwind CSS v4, TanStack Query 5, Zustand 5, React Router 7 |
| **UI Components** | Radix UI, Recharts, XYFlow, cmdk, Lucide Icons, Sonner |
| **Backend** | Fastify 5, TypeScript 5.7, Socket.IO 4, Zod, Jose (JWT), bcrypt |
| **Database** | PostgreSQL 17 (pg client), TimescaleDB (metrics), automated pg_dump backups via cron sidecar |
| **AI** | Ollama (local LLM), optional OpenWebUI support |
| **Logging** | Pino (backend), optional Elasticsearch log shipping via `_bulk` API (batched, retry with backoff) |
| **DevOps** | Docker, Docker Compose, GitHub Actions CI |
| **Testing** | Vitest, Testing Library, jsdom, Playwright (E2E) |

## Docker Development

### Standard Development Stack
```bash
docker compose -f docker/docker-compose.dev.yml up -d
```

Runs backend (Fastify) and frontend (Vite) in hot-reload containers with auto-refresh on code changes.

### Edge Agent Testing
```bash
docker compose -f docker/docker-compose.edge-agent.yml up -d
```

Runs a **Portainer Edge Agent Standard** container locally for testing Edge features (e.g., endpoints registered as edge agents). Requires `EDGE_AGENT_ID` and `EDGE_AGENT_KEY` environment variables in `docker/.env` (obtained from Portainer UI when enrolling an edge agent). Port 8000 must be exposed on the Portainer instance for Edge tunnels.

### Test Database Setup

Backend tests use a **real PostgreSQL test database** instead of mocks or in-memory databases:

- **Database**: `portainer_dashboard_test` on port **5433** (mapped from container port 5432)
- **Initialization**: `docker/init-test-db.sh` creates the test database when the `postgres-app` container starts
- **Test Utilities**: `backend/src/db/test-db-helper.ts` provides:
  - `getTestDb()` — Returns a PostgreSQL pool connected to the test database
  - `getTestPool()` — Returns the raw `pg.Pool` for advanced usage
  - `truncateTestTables()` — Clears all tables between tests
  - `closeTestDb()` — Closes the test pool connection
- **Migrations**: Production migrations from `backend/src/db/postgres-migrations/` are automatically applied to the test database
- **Configuration**: Set `POSTGRES_TEST_URL` environment variable to override the default connection string (default: `postgresql://postgres:postgres@localhost:5433/portainer_dashboard_test`)
- **CI Support**: GitHub Actions workflow includes a `postgres-test` service container for running tests in CI

**Running Tests**:
```bash
# All backend tests (requires test DB running)
npm run test -w backend

# Single test file
cd backend && npx vitest run src/path/to/file.test.ts

# Start test database
docker compose -f docker/docker-compose.dev.yml up -d postgres-app
```

**Important**: Backend tests use `fileParallelism: false` in vitest config because tests share database tables. This ensures tests run sequentially to avoid conflicts.

---

## Project Structure

```
ai-portainer-dashboard/
├── backend/                        # Fastify API server
│   └── src/
│       ├── routes/                 # REST API endpoints
│       │   ├── auth.ts             #   Authentication (login/logout/refresh)
│       │   ├── containers.ts       #   Container listing & details
│       │   ├── metrics.ts          #   Time-series metrics & anomalies
│       │   ├── monitoring.ts       #   Insights & acknowledgments
│       │   ├── remediation.ts      #   Action approval workflow
│       │   ├── settings.ts         #   Configuration & audit log
│       │   ├── harbor-vulnerabilities.ts #  Harbor vulnerability management API
│       │   ├── security-regression.test.ts # Auth sweep, injection vectors, rate limits
│       │   └── ...                 #   Dashboard, endpoints, images, etc.
│       ├── services/               # Business logic
│       │   ├── portainer-client.ts #   Portainer API (retry + backoff + circuit breaker)
│       │   ├── circuit-breaker.ts #   Generic circuit breaker (CLOSED→OPEN→HALF_OPEN)
│       │   ├── portainer-cache.ts  #   Response caching (TTL)
│       │   ├── portainer-client.ts #   Portainer API (retry + backoff)
│       │   ├── portainer-cache.ts  #   Hybrid cache (L1 in-memory + Redis L2, exponential backoff)
│       │   ├── llm-client.ts       #   Ollama LLM integration
│       │   ├── prompt-guard.ts    #   3-layer prompt injection defense (regex + heuristic + output)
│       │   ├── adaptive-anomaly-detector.ts # Multi-method anomaly detection
│       │   ├── isolation-forest.ts #   Isolation Forest ML algorithm
│       │   ├── isolation-forest-detector.ts # IF model caching + detection
│       │   ├── log-analyzer.ts     #   NLP log analysis (LLM)
│       │   ├── alert-similarity.ts #   Jaccard text similarity grouping
│       │   ├── incident-correlator.ts # Alert → incident correlation
│       │   ├── incident-summarizer.ts # LLM incident summaries
│       │   ├── monitoring-service.ts#  Monitoring cycle orchestration
│       │   ├── metrics-collector.ts#   CPU/memory collection
│       │   ├── otel-exporter.ts   #   OTLP/HTTP JSON span export to external collectors
│       │   ├── harbor-client.ts  #   Harbor Registry API client (vulnerability data)
│       │   ├── harbor-sync.ts    #   Periodic vulnerability sync from Harbor
│       │   └── ...                 #   Sessions, settings, audit, backup
│       ├── sockets/                # Socket.IO namespaces
│       │   ├── llm-chat.ts         #   /llm — streaming chat
│       │   ├── monitoring.ts       #   /monitoring — live insights
│       │   └── remediation.ts      #   /remediation — action updates
│       ├── scheduler/              # Background jobs
│       │   └── setup.ts            #   Metrics (60s), monitoring (5m), cleanup (daily)
│       ├── db/
│       │   ├── postgres.ts         #   App PostgreSQL pool + migration runner
│       │   ├── app-db.ts           #   AppDb interface (async DB abstraction)
│       │   ├── app-db-router.ts    #   Routes domains to PostgreSQL adapter
│       │   ├── postgres-adapter.ts #   PostgreSQL AppDb implementation
│       │   ├── timescale.ts        #   TimescaleDB pool (metrics/KPI)
│       │   └── postgres-migrations/ #  22 PostgreSQL migration files
│       ├── models/                 # Zod schemas & DB queries
│       ├── utils/                  # Crypto (JWT/bcrypt), logging (Pino + ES transport)
│       └── plugins/                # Fastify plugins
├── frontend/                       # React SPA
│   ├── scripts/
│   │   └── check-bundle-size.ts   # Gzip budget checker (CI enforced)
│   ├── bundle-size.config.json    # Per-chunk gzip budgets
│   └── src/
│       ├── pages/                  # 18 lazy-loaded page components
│       ├── components/
│       │   ├── layout/             #   App layout, header, sidebar, command palette
│       │   ├── charts/             #   Metrics, pie, bar, sparkline, treemap, sunburst
│       │   ├── container/          #   Container overview, metrics, logs viewers
│       │   ├── network/            #   XYFlow topology graph & nodes
│       │   └── shared/             #   Data table, KPI cards, badges, skeletons
│       ├── hooks/                  # TanStack React Query hooks (25 hooks)
│       ├── stores/                 # Zustand stores (theme, UI, notifications, filters)
│       ├── providers/              # Auth, Socket.IO, Theme, React Query providers
│       └── lib/                    # API client, socket manager, CSV export
├── scripts/
│   └── deploy-workload.sh          # Test workload deployment script
├── docker/                          # All Dockerfiles and compose files
│   ├── docker-compose.yml          # Production (Nginx + Node)
│   ├── docker-compose.dev.yml      # Development (hot-reload)
│   ├── docker-compose.loadtest.yml # Load testing suite
│   ├── docker-compose.security-mcp.yml # Security MCP servers
│   ├── backend/
│   │   ├── Dockerfile              # Backend production image
│   │   └── Dockerfile.dev          # Backend dev image (hot-reload)
│   ├── frontend/
│   │   ├── Dockerfile              # Frontend production image
│   │   └── Dockerfile.dev          # Frontend dev image (hot-reload)
│   ├── loadtests/
│   │   └── Dockerfile              # Load testing image
│   ├── kali-mcp/
│   │   └── Dockerfile              # Kali MCP server image
│   ├── grype-mcp/
│   │   └── Dockerfile              # Grype MCP server image
│   ├── nvd-mcp/
│   │   └── Dockerfile              # NVD MCP server image
│   ├── snyk-mcp/
│   │   └── Dockerfile              # Snyk MCP server image
│   └── beyla/
│       └── beyla.yml               # eBPF auto-instrumentation sidecar
├── e2e/                               # Playwright E2E tests
│   ├── auth.spec.ts                   #   Login, logout, session redirect
│   ├── navigation.spec.ts            #   Sidebar navigation, breadcrumbs, 404
│   ├── containers.spec.ts            #   Container list, search, detail nav
│   ├── settings.spec.ts              #   Theme persistence, tab navigation
│   ├── global-setup.ts               #   Auth state caching (→ .auth/user.json)
│   └── helpers/
│       └── login.ts                   #   Shared login helper
├── workloads/                       # Multi-stack test workload compose files
│   ├── data-services.yml            #   Postgres, Redis, RabbitMQ
│   ├── web-platform.yml             #   Web tier + API gateway + cron
│   ├── workers.yml                  #   Workers + app-api + app-worker-queue
│   ├── staging-dev.yml              #   Staging + dev environments + monitoring
│   └── issue-simulators.yml         #   Issue containers + heavy-load stress
└── .github/workflows/ci.yml        # CI: typecheck → lint → test → build
```

---

## Workload Explorer Grouping

Workload Explorer includes first-class container grouping for operational agents and app workloads:

- `System` group: containers detected as Edge Agent/Beyla using name/image/label patterns.
- `Workload` group: all other containers.
- CSV export runs on the visible filtered rows (endpoint/stack/group) to keep exports aligned with what users see.

Detailed matching patterns are documented in `docs/workload-explorer-system-grouping.md`.

---

## External Agent System Architecture

For documentation related to the underlying AI agent framework, which includes components like the `ModularStrategy`, multi-strategy code execution environments, and the generic model abstraction layer, please refer to the separate architecture document:

-   **[Agent System Architecture (`/ARCHITECTURE.md`)](<../ARCHITECTURE.md>)**

*Note: This document describes the general-purpose agent framework, while the documentation above describes the specific architecture of the AI Portainer Dashboard application.*
